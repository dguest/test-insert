This analysis considered all data taken at the LHC in $\cmenergy$ proton-proton collisions, recorded beginning early 2012 and continuing throughout the year.
In this time, the LHC accumulated total of $20.3 \pm 2.8\%\,\invfb$ of integrated luminosity after various data-cleaning requirements were applied.
An additional $\sim 4.7\,\invfb$ of $\sqrt{s} = 7\,\tev$, taken in 2011, was not considered due to lower signal cross-sections, limited gain in data, and the complexity of combining datasets with different collision energies.

As discussed in \cref{sec:trigger}, only a very small fraction of collisions in ATLAS are ever recorded, so in addition to being measurable at the LHC, signatures must match events which fire a trigger.

\subsection{$\met$ Trigger}
The signature of a $\sctoc$ decay is several $c$-jets plus $\met$.
Charm-tagging isn't possible at trigger-level given the short timescales involved and the complexity of $c$-tagging.
This leaves generic jets and $\met$ as trigger options.
Of these, jet triggers are set with very high thresholds because jets are so common in hadron collisions; most of the jets $\sctoc$ would be below these thresholds.
This leaves only $\met$ triggers as a viable option. \Cref{fig:etmiss-triggers} shows the efficiency of the $\met$ trigger used in this analysis (\verb|EF_xe80_tclcw_tight|). While the trigger threshold is, by design, roughly $80 \,\gev$, it only becomes $\sim 98\%$ efficient at approximately $150\,\gev$ due to the limited resolution of online $\met$ reconstruction.
Typically data and simulation disagree somewhat in trigger efficiency; to mitigate any systematic uncertainty arising form this disagreement, events must satisfy an offline $\met > 150\,\gev$ requirement.

%% \begin{table}
%% \begin{center}
%% \begin{tabular}{|c|r|r|}
%% \hline
%% Period & Luminosity (pb$^{-1}$) & Percentage of total luminosity \\
%% \hline
%% A & 794.02 & 3.9 \\
%% B & 5090.83 & 25.1 \\
%% C & 1406.02 & 6.9 \\
%% D & 3288.33 & 16.2 \\
%% E & 2526.28 & 12.5 \\
%% G & 1274.23 & 6.3 \\
%% H & 1444.93 & 7.1 \\
%% I & 1016.26 & 5.0 \\
%% J & 2596.34 & 12.8 \\
%% L & 839.77 & 4.1 \\
%% \hline
%% Total & 20276.9 & 100.0\\
%% \hline
%% \end{tabular}
%% \end{center}
%% \caption{Luminosity after livefraction and LAr veto corrections collected with {\tt EF\_xe80\_tclcw\_tight} in each data taking period.\label{tab:lumiByPeriod}}
%% \end{table}

\begin{figure}
  \includegraphics[width=0.49\textwidth]{%
int/figures/trigger/EF_xe80_tclcw_tight_efficiency_addLep_periodD.pdf}
  \includegraphics[width=0.49\textwidth]{%
int/figures/trigger/EF_xe80_tclcw_tight_efficiency_addLep_WmunuMC_leg.pdf}
  \caption[$\met$ trigger efficienty]{Trigger efficiency for the $\met$ trigger. The left plot shows trigger efficiency in data, while the right shows efficiency in simulated $W \to \mu\nu$ events. A solid horizontal line indicates 100\% efficiency, while the dark dotted and light dotted lines indicate 98\% and 95\% efficiency. The vertical dotted line indicates the offline $\met$ requirement used in this search.}
  \label{fig:etmiss-triggers}
\end{figure}

\subsection{Lepton Triggers}
Background estimation is discussed in more detail in \cref{sec:backgrounds}, but to control for the larger backgrounds, we also require data with 1 or 2 leptons.
The dominating background processes produce leptons through electroweak interactions, and thus give rise to roughly equal numbers of all three lepton generations.
Of the three generations, $\tau$-leptons are exceptionally difficult to reconstruct and carry relatively large systematic uncertainties.
Thus $\tau$-leptons are ignored in control regions which constrain the dominant backgrounds; events within control regions are selected by muon and electron triggers.

\begin{table}
\begin{center}
\begin{tabular}{ | l | l | l | l | }
\hline
Channel & Trigger chain & Offline Thresholds \\ \hline
1-electron & \texttt{EF\_e24vhi\_medium1} OR \texttt{EF\_e60\_medium1} & $\pt(e)>25$~GeV \\
\hline
1-muon  & \texttt{EF\_mu24i\_tight} OR \texttt{EF\_mu36\_tight} & $\pt(\mu)>25$~GeV\\
\hline
%% 2-electron & \texttt{EF\_e24vhi\_medium1} OR \texttt{EF\_e60\_medium1} & $\pt(e)>25$~GeV \\
%% \hline
%% 2-muon & \texttt{EF\_mu24i\_tight} OR \texttt{EF\_mu36\_tight} & $\pt(\mu)>25$~GeV \\
%% \hline
%% 1-e, 1-mu & same as single $e/\mu$ triggers (overlap removed) & $\pt(e/\mu)>25$~GeV \\
%% \hline
\end{tabular}
\caption[Lepton Triggers]{%
Lepton triggers used in the $\sctoc$ analysis.
The \texttt{el*} and \texttt{mu*} strings indicate electron and muon triggers, respectively, where the following number indicates the online lepton threshold.
Triggers with \texttt{vhi} or \texttt{i} require isolated leptons, while \texttt{medium}, \texttt{tight} etc.\ indicate reconstruction quality requirements.
Generally isolated low-$\pt$ lepton triggers are combined with high-$\pt$ lepton triggers.
The third column indicates the offline $\pt$ requirements.
}
\label{tab:lepton-triggers}
\end{center}
\end{table}

In general, the lowest non-prescaled trigger which is available for the entire 2012 data set is used.
As with the $\met$ trigger, an offline threshold is required to ensure that the trigger is nearly $100\,\%$ efficient.
In control regions which require two leptons, dilepton triggers were considered since they allow lower offline $\pt$ thresholds (20 as opposed to 25 $\gev$).
As discussed further in \cref{sec:dilepton-triggers}, these were rejected because the final control region definitions included a leading lepton requirement $\pt > 70\,\gev$; lowering the $\pt$ threshold on the leading lepton added very few events, and a $\pt > 20\,\gev$ requirement on the second lepton removed many more.
